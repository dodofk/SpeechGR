# @package _global_

ssl:
  model_name: "microsoft/wavlm-large"
  layer: 24

rqvae:
  latent_dim: 1024
  codebook_size: 256
  num_codebooks: 8
  commitment_cost: 0.25
  decay: 0.99
  num_encoder_layers: 4
  num_decoder_layers: 4

data:
  manifest_path: ???
  val_manifest: null
  max_length: 160000 # 10 seconds
  num_workers: 4

training:
  batch_size: 32
  lr: 1e-4
  epochs: 50
  save_steps: 1000

logging:
  project: "speechgr-rqvae"
  name: "rqvae_transformer_ema"
  mode: "online" # set to "disabled" to skip wandb

hydra:
  run:
    dir: outputs/rqvae/${now:%Y-%m-%d}/${now:%H-%M-%S}
