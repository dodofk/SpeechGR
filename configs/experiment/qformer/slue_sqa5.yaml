defaults:
  - override /task: qformer
  - _self_

model:
  model_name: "google/flan-t5-base"
  model_type: "qformer"
  n_queries: 1
  qformer_depth: 2
  win_size_f: 17
  win_stride_f: 17
  freeze_t5_encoder: false
  use_whisper_features: false

data:
  code_path: "/home/ricky/dodofk/dataset/slue_sqa_code_l22_c500"
  discrete_code_num: 500
  special_token: 32000

qformer:
  max_length: 272
  run_notes: "Train flant5-base + qformer with 500 discrete unit on layer 22 with 1 query per window and 17 window size and stride"

training:
  training_args:
    output_dir: "models/slue_sqa5-flan-t5-base-qformer-N1-D2-L17-S17-du-l22-c500-fte"
    run_name: "slue_sqa5-flan-t5-base-qformer-N1-D2-L17-S17-du-l22-c500-fte"
    learning_rate: 1.0e-4
    warmup_steps: 5000
    per_device_train_batch_size: 36
    per_device_eval_batch_size: 8
    gradient_accumulation_steps: 4
    evaluation_strategy: "steps"
    eval_steps: 1000
    max_steps: 250000
    save_strategy: "steps"
    save_steps: 1000
    save_total_limit: 4
    load_best_model_at_end: true
    metric_for_best_model: "Hits@20"
    greater_is_better: true
    save_safetensors: true
    logging_steps: 50
    dataloader_num_workers: 0
    dataloader_drop_last: false
