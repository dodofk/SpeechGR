defaults:
  - override /task: t5_pretrain
  - _self_

model:
  model_name_or_path: "google/flan-t5-base"
  final_model_dir: "models/t5-pretrain/flan-t5-base-slue"
  sentinel_start_id: 32000

data:
  code_dir: ${oc.env:SLUE_SQA5_CODE_PATH,${hydra:runtime.cwd}/outputs/slue_wavtok/precomputed}
  seq_length: 512
  chunk_offset: 50
  discrete_code_num: 512
  mask_prob: 0.15
  mean_span_length: 3

wandb:
  project: "Audio-T5-Pretrain"
  description: "SLUE discrete unit span corruption"

training:
  training_args:
    output_dir: "models/t5-pretrain/flan-t5-base-slue/checkpoints"
    run_name: "t5-pretrain-slue"
    per_device_train_batch_size: 64
    per_device_eval_batch_size: 64
    learning_rate: 1e-4
    warmup_steps: 2000
    num_train_epochs: 10
    evaluation_strategy: "steps"
    eval_steps: 2000
    save_strategy: "steps"
    save_steps: 2000
    save_total_limit: 5
    logging_steps: 200
    bf16: true
    gradient_accumulation_steps: 2
